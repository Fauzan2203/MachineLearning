{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Lth2WXRPFJi9"
      },
      "outputs": [],
      "source": [
        "# Muhammad Fauzan Nur'ilham\n",
        "# 1103204085\n",
        "# Machine Learning\n",
        "# TK-44-G4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengimpor pustaka yang diperlukan dari PyTorch untuk membangun dan melatih jaringan saraf\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Menyiapkan komponen-komponen yang diperlukan untuk membangun dan melatih jaringan saraf menggunakan PyTorch\n",
        "# - torch: Pustaka PyTorch untuk komputasi tensor\n",
        "# - torch.nn: Modul jaringan saraf PyTorch untuk membangun dan melatih jaringan saraf\n",
        "# - torch.optim: Modul optimisasi PyTorch untuk menentukan dan menggunakan algoritma optimisasi\n",
        "# - torchvision: Pustaka PyTorch untuk menangani dataset dan model penglihatan komputer\n",
        "# - torchvision.transforms: Modul PyTorch untuk mendefinisikan transformasi gambar\n",
        "# - torch.utils.data: Modul PyTorch untuk menangani pengambilan data dan pembuatan batch"
      ],
      "metadata": {
        "id": "Hp7hA7qCJhIX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Memilih perangkat (device) yang akan digunakan, jika CUDA (GPU) tersedia, gunakan CUDA, jika tidak, gunakan CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "NwFIlQA275rc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mendefinisikan kelas AlexNetMNIST sebagai turunan dari nn.Module\n",
        "class AlexNetMNIST(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AlexNetMNIST, self).__init__()\n",
        "\n",
        "        # Definisi layer-layer dari arsitektur AlexNet\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        )\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, 10),  # 10 classes for MNIST\n",
        "        )\n",
        "\n",
        "    # Definisi langkah-langkah forward propagation\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "fqvkqkTA7_ds"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menentukan serangkaian transformasi untuk preprocessing data\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Mengubah ukuran gambar menjadi (224, 224)\n",
        "    transforms.ToTensor(),  # Mengubah gambar menjadi tensor PyTorch\n",
        "])"
      ],
      "metadata": {
        "id": "XsxCLRvw8V66"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torchvision.datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7UZz9I78aPb",
        "outputId": "d01a25ac-ff42-41ac-8164-30f4b3460974"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 132334656.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 15884565.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 109603819.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 4156781.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "VVf8Pynv8fC4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat instance dari kelas AlexNetMNIST dan memindahkannya ke perangkat yang telah dipilih\n",
        "model = AlexNetMNIST().to(device)\n",
        "\n",
        "# Menentukan fungsi loss (CrossEntropyLoss) untuk klasifikasi multikelas\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Menentukan algoritma optimisasi (Adam) dengan learning rate sebesar 0.001\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "8E6sukfe8hOo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menentukan jumlah epoch\n",
        "num_epochs = 5\n",
        "\n",
        "# Melakukan iterasi untuk setiap epoch\n",
        "for epoch in range(num_epochs):\n",
        "    # Mengaktifkan mode pelatihan pada model\n",
        "    model.train()\n",
        "\n",
        "    # Menginisialisasi total_loss untuk setiap epoch\n",
        "    total_loss = 0.0\n",
        "\n",
        "    # Iterasi untuk setiap batch pada data pelatihan\n",
        "    for inputs, labels in train_loader:\n",
        "        # Memindahkan data ke perangkat yang telah ditentukan sebelumnya (cuda/cpu)\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Mengatur gradien parameter model menjadi 0\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Melakukan forward pass\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Menghitung nilai fungsi loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Melakukan backward pass dan optimasi parameter model\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Menambahkan nilai loss pada total_loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Menampilkan informasi hasil pelatihan pada setiap epoch\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss / len(train_loader)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MedUTZUI9wa5",
        "outputId": "e2b7703e-9d7b-4334-fbcb-72042e9d436f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.27832232897571013\n",
            "Epoch 2/5, Loss: 0.0874824858247501\n",
            "Epoch 3/5, Loss: 0.07202413928474603\n",
            "Epoch 4/5, Loss: 0.06031352254287921\n",
            "Epoch 5/5, Loss: 0.05407678246641952\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Menentukan jumlah epoch\n",
        "num_epochs = 5\n",
        "\n",
        "# Melakukan iterasi untuk setiap epoch\n",
        "for epoch in range(num_epochs):\n",
        "    # Mengaktifkan mode pelatihan pada model\n",
        "    model.train()\n",
        "\n",
        "    # Menginisialisasi total_loss untuk setiap epoch\n",
        "    total_loss = 0.0\n",
        "\n",
        "    # Iterasi untuk setiap batch pada data pelatihan\n",
        "    for inputs, labels in train_loader:\n",
        "        # Memindahkan data ke perangkat yang telah ditentukan sebelumnya (cuda/cpu)\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Mengatur gradien parameter model menjadi 0\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Melakukan forward pass\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Menghitung nilai fungsi loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Melakukan backward pass dan optimasi parameter model\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Menambahkan nilai loss pada total_loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Menampilkan informasi hasil pelatihan pada setiap epoch\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss / len(train_loader)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjgRy0wy970Y",
        "outputId": "69624e8a-fe74-479f-f2a2-1e0ac8912e94"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.05119844949766082\n",
            "Epoch 2/5, Loss: 0.04783052914441555\n",
            "Epoch 3/5, Loss: 0.045192258018747544\n",
            "Epoch 4/5, Loss: 0.039444816615593375\n",
            "Epoch 5/5, Loss: 0.039022260581911584\n"
          ]
        }
      ]
    }
  ]
}